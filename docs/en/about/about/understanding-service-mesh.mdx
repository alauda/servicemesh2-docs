---
weight: 20
---

# Understanding Alauda Service Mesh

Alauda Service Mesh is composed of two parts:

- Alauda Service Mesh resources
- Alauda Build of Kiali

Alauda Build of Kiali is composed of two parts:

- Kiali Operator provided by Alauda
- Kiali Server

Alauda Service Mesh integrates with the following:

- Observability components such as:
  - Monitoring components such as:
    - Prometheus
    - VictoriaMetrics
  - Alauda Build of Jaeger
  - Alauda Build of OpenTelemetry
- cert-manager
- Flagger

## Alauda Service Mesh resources

Alauda Service Mesh v2 Operator manages the lifecycle of your Istio control planes. Instead of creating a new configuration schema, Alauda Service Mesh v2 Operator APIs are built around Istio's Helm chart APIs.

:::note
- Though Alauda Service Mesh APIs are built around Istio's Helm chart APIs, Helm charts are not supported.
- All installation and configuration options that are exposed by Istio's Helm charts are available through the Alauda Service Mesh Custom Resource Definition (CRD) `values` fields.
:::

### Istio resource

The `Istio` resource is used to manage your Istio control planes. It is a cluster-wide resource, because the Istio control plane operates in and requires access to the entire cluster.

To select a namespace to run the control plane pods in, you can use the `spec.namespace` field.

:::note
The `spec.namespace` field is immutable: in order to move a control plane to another namespace, you must remove the `Istio` resource and recreate it with a different `spec.namespace`.
:::

You can access all `Istio` custom resource definition (CRD) options through `spec.values` fields:

**Example Istio resource CRD**

```yaml
apiVersion: sailoperator.io/v1
kind: Istio
metadata:
  name: default
spec:
  version: v1.26.2
  namespace: istio-system
  updateStrategy:
    type: InPlace
  values:
    pilot:
      resources:
        requests:
          cpu: 100m
          memory: 1024Mi
```

You can run the following command to see all the customization options:

```bash
kubectl explain istios.spec.values
```

To perform canary updates of the control plane, Alauda Service Mesh supports multiple Istio versions. You can set the `version` field to the new version by either using the full version or the `v<x>.<y>-latest` alias to automatically select the latest version for a specific minor version. For example, setting `v1.23-latest` ensures that the Operator maintains the latest version of Istio 1.23.

Alauda Service Mesh supports two different update strategies for your control planes:

`InPlace`

The Alauda Service Mesh v2 Operator immediately replaces your existing control plane resources with the ones for the new version.

`RevisionBased`

Uses Istio's canary update mechanism by creating a second control plane to which you can migrate your workloads to complete the update.

After creating an Istio resource, Alauda Service Mesh generates a revision name for the resource based on the `updateStrategy`, and creates a corresponding `IstioRevision`.

### IstioRevision resource

The `IstioRevision` is a cluster-wide resource and the lowest-level API Alauda Service Mesh provides. It is usually not created by the user, but by the Operator itself. Its schema closely resembles that of the `Istio` resource - but instead of representing the state of a control plane you want to be present in your cluster, it represents a revision of that control plane.

A revision of the control plane you want to be present in your cluster is an instance of Istio with a specific version and revision name, and its revision name can be used to add workloads or entire namespaces to the mesh. For example: by using the `istio.io/rev=<REVISION_NAME>` label.

You can think of the relationship between the `Istio` and `IstioRevision` resources as similar to the relationship between Kubernetes' replica set and pod: a replica set can be created by users and results in the automatic creation of pods, which will trigger the instantiation of your containers.

Similarly, users create an `Istio` resource which instructs the Alauda Service Mesh v2 Operator to create a matching `IstioRevision` resource, which then in turn triggers the creation of the Istio control plane. To do that, the Alauda Service Mesh v2 Operator will copy all of your relevant configuration from the `Istio` resource to the `IstioRevision` resource.

### IstioRevisionTag resource

The `IstioRevisionTag` resource represents a stable revision tag that functions as an alias for Istio control plane revisions. With the stable tag, `prod`, you can use the label `istio.io/rev=prod` to inject proxies into your workloads. When you perform an upgrade to a control plane with a new revision name, you can update your tag to point to the new revision instead of having to relabel your workloads and namespaces. For more information, see [Stable revision labels](https://istio.io/latest/docs/setup/upgrade/canary/#stable-revision-labels) (Istio documentation).

You can use the `IstioRevisionTag` resource with the Alauda Service Mesh v2 Operator. Therefore you can reference both an `IstioRevision` and an `Istio` resource. When using an `Istio` resource, after you update your control plane, the underlying `IstioRevision` resource changes, and the Alauda Service Mesh v2 Operator automatically updates your revision tag. You only need to restart your deployments to re-inject the new proxies.

The `IstioRevisionTag` has one field in its `spec:` field, `targetRef`, which can reference an `Istio` or `IstioRevision` resource. After deploying the `IstioRevisionTag`, you can use both the `istio.io/rev=default` and `istio-injection=enabled` labels to inject proxies into your workloads.

The `istio-injection` label can only be used for revisions and revision tags that have the name `default`, like the `IstioRevisionTag` resource in the following example:

**Example `IstioRevisionTag` resource**

```yaml
apiVersion: sailoperator.io/v1
kind: IstioRevisionTag
metadata:
  name: default
spec:
  targetRef:
    kind: Istio  # [!code callout]
    name: prod  # [!code callout]
```

<Callouts>
  1. This value can be either `Istio` or `IstioRevision`.
  2. The name of the `Istio` or `IstioRevision` resource.
</Callouts>

### IstioCNI resource

The lifecycle of Istio's Container Network Interface (CNI) plugin is managed separately when using Alauda Service Mesh v2 Operator. To install Istio's CNI plugin, you create an `IstioCNI` resource.

The `IstioCNI` resource is a cluster-wide resource as it installs a daemon set that operates on all nodes of your cluster. You can select a version by setting the `spec.version` field, as you can see in the example that follows. To update the CNI plugin, change the version field to the version you want to install. Like the `Istio` resource, it also has a `values` field that exposes all of the options provided in the `istio-cni` chart:

**Example `IstioCNI` resource**

```yaml
apiVersion: sailoperator.io/v1
kind: IstioCNI
metadata:
  name: default
spec:
  version: v1.26.2
  namespace: istio-cni
  values:
    cni:
      cniConfDir: /etc/cni/net.d
      excludeNamespaces:
      - kube-system
```

## Alauda Build of Kiali

Kiali is based on the open source Kiali project. See [Kiali project](https://kiali.io/). Alauda Build of Kiali is composed of two parts:

- Kiali Operator provided by Alauda
- Kiali Server

Working together, they form the user interface (UI) for Alauda Service Mesh. Kiali provides visibility into your service mesh by showing you the microservices and how they are connected.

Kiali helps you define, validate, and observe your Istio service mesh. It helps you to understand the structure of your service mesh by inferring the topology, and also provides information about the health of your service mesh.

Kiali provides an interactive graph view of your mesh namespaces in near real time that provides visibility into features like circuit breakers, request rates, latency, and even graphs of traffic flows. Kiali offers insights about components at different levels, such as applications, services, workloads, and can display the interactions with contextual information and charts on the selected graph node or edge.

Kiali also provides the ability to validate your Istio configurations, such as gateways, destination rules, virtual services, mesh policies, and so on. Kiali provides detailed metrics, and a basic Grafana integration is available for advanced queries. Distributed tracing is provided by Alauda Build of Jaeger and Alauda Build of OpenTelemetry.

### Kiali architecture

#### Kiali Server (back end)

This component runs in the container application platform and communicates with the service mesh components, retrieves and processes data, and exposes this data to the console. The Kiali Server does not need storage. When deploying the Server to a cluster, configurations are set in config maps and secrets.

#### Kiali console (front end)

The Kiali console is a web application. The console queries the Kiali Server for data to present it to the user.

In addition, Kiali depends on external services and components provided by the container application platform and Istio.

#### Alauda Service Mesh (Istio)

Istio is a Kiali requirement. Istio is the component that provides and controls the service mesh. Although Kiali and Istio can be installed separately, Kiali depends on Istio and will not work if it is not present. Kiali needs to retrieve Istio data and configurations, which are exposed through Prometheus and the Alauda Service Mesh cluster API.

#### Prometheus

A dedicated Prometheus instance is optional. When Istio telemetry is enabled, metrics data are stored in Prometheus. Kiali uses this Prometheus data to determine the mesh topology, display metrics, calculate health, show possible problems, and so on. Kiali communicates directly with Prometheus and assumes the data schema used by Istio Telemetry. Prometheus is an Istio dependency and a hard dependency for Kiali, and many of Kiali's features will not work without Prometheus.

#### Alauda Container Platform API

Kiali uses the Alauda Container Platform API to fetch and resolve service mesh configurations. For example, Kiali queries the cluster API to retrieve definitions for namespaces, services, deployments, pods, and other entities. Kiali also makes queries to resolve relationships between the different cluster entities. The cluster API is also queried to retrieve Istio configurations like virtual services, destination rules, route rules, gateways, quotas, and so on.

#### Tracing

Tracing is optional, but when you install Jaeger and OpenTelemetry is configured, the Kiali console includes a tab to display distributed tracing data, and tracing integration on the graph itself. Note that tracing data will not be available if you disable Istio's distributed tracing feature. Also note that the user must have access to the namespace where the user needs to see tracing data.

#### Grafana

Grafana is optional. When available, the metrics pages of Kiali display links to direct the user to the same metric in Grafana. Note that Grafana is not supported Alauda Container Platform or Alauda Service Mesh.

### Kiali features

The Kiali console is integrated with Alauda Service Mesh and provides the following capabilities:

#### Health

Quickly identify issues with applications, services, or workloads.

#### Topology

Visualize how your applications, services, or workloads communicate through the Kiali graph.

#### Metrics

Predefined metrics dashboards let you chart service mesh and application performance for Go, Node.js. Quarkus, Spring Boot, Thorntail and Vert.x. You can also create your own custom dashboards.

#### Tracing

Integration Jaeger lets you follow the path of a request through various microservices that make up an application.

#### Validations

Perform advanced validations on the most common Istio objects (Destination Rules, Service Entries, Virtual Services, and so on).

#### Configuration

Optional ability to create, update, and delete Istio routing configuration using wizards or directly in the YAML editor in the Kiali Console.

## Alauda Service Mesh and Observability

### Monitoring

Monitoring components such as Prometheus or VictoriaMetrics can be deployed in Alauda Container Platform.

When you have added your application to the mesh, you can monitor the in-cluster health and performance of your applications running on Alauda Container Platform with metrics and customized alerts for CPU and memory usage, network connectivity, and other resource usage.

### Distributed Tracing

Alauda Service Mesh uses Alauda Build of Jaeger to allow developers to view call flows in a microservice application.

Integrating Alauda Build of Jaeger with Alauda Service Mesh is made of up two parts: Alauda Build of Jaeger and Alauda Build of OpenTelemetry.

#### Alauda Build of Jaeger

Is based on the open source [Jaeger](https://www.jaegertracing.io/) project, provides distributed tracing to monitor and troubleshoot transactions in complex distributed systems.

#### Alauda Build of OpenTelemetry

Is based on the open source OpenTelemetry project, which aims to provide unified, standardized, and vendor-neutral telemetry data collection for cloud-native software. Alauda Build of OpenTelemetry product provides support for deploying and managing the OpenTelemetry Collector and simplifying the workload instrumentation. See [OpenTelemetry project](https://opentelemetry.io/)

The OpenTelemetry Collector can receive, process, and forward telemetry data in multiple formats, making it the ideal component for telemetry processing and interoperability between telemetry systems. The Collector provides a unified solution for collecting and processing metrics, traces, and logs. See [OpenTelemetry Collector](https://opentelemetry.io/docs/collector/).
